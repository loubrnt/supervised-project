## üèéÔ∏è Chargement et Optimisation des Donn√©es

La premi√®re √©tape consiste √† charger les donn√©es en optimisant l'utilisation de la m√©moire, en ne s√©lectionnant que les colonnes utiles (`usecols`) et en sp√©cifiant des types de donn√©es plus l√©gers (`dtype`).

### Pourquoi optimiser le chargement ?

L'optimisation de la m√©moire est **cruciale** pour plusieurs raisons :
* **Performance** : R√©duire l'empreinte m√©moire permet un traitement plus rapide et √©vite les ralentissements
* **Scalabilit√©** : Permet de travailler sur des machines avec des ressources limit√©es
* **Co√ªt** : Moins de RAM n√©cessaire = possibilit√© de travailler sur des environnements cloud moins co√ªteux
* **Efficacit√©** : En ne chargeant que les colonnes n√©cessaires, on √©vite de polluer notre environnement de travail avec des donn√©es inutiles

### Configuration du Chargement

| Fichier | Colonnes S√©lectionn√©es (`usecols`) | Types Sp√©cifi√©s (`dtypes`) |
| :--- | :--- | :--- |
| **`vehicle.csv`** | `collision_index`<br>`age_of_driver`<br>`propulsion_code`<br>`vehicle_type`<br>`age_of_vehicle`<br>`sex_of_driver` | `collision_index: object`<br>`vehicle_type: int8`<br>`age_of_driver: int8`<br>`age_of_vehicle: int8`<br>`propulsion_code: int8`<br>`sex_of_driver: int8` |
| **`collision.csv`** | `collision_index`<br>`urban_or_rural_area`<br>`speed_limit`<br>`date`<br>`road_type`<br>`light_conditions`<br>`weather_conditions`<br>`collision_severity`<br>`local_authority_ons_district`<br>`time` | `collision_index: object`<br>`road_type: int8`<br>`light_conditions: int8`<br>`weather_conditions: int8`<br>`collision_severity: int8`<br>`urban_or_rural_area: int8`<br>`speed_limit: float32` |

### Choix des types de donn√©es

Le choix des types est strat√©gique :
* **`int8`** : Pour les variables cat√©gorielles avec peu de modalit√©s (< 127 valeurs). Utilise seulement 1 octet par valeur au lieu de 8 octets pour un `int64` standard
* **`float32`** : Pour `speed_limit` qui n√©cessite des d√©cimales mais pas une pr√©cision extr√™me. Utilise 4 octets au lieu de 8 pour `float64`
* **`object`** : Pour `collision_index` car c'est un identifiant textuel unique qui ne peut pas √™tre converti en entier

### Impact sur la M√©moire

| Fichier | M√©moire (Avant Optimisation) | M√©moire (Apr√®s Optimisation) | R√©duction |
| :--- | :--- | :--- | :--- |
| `vehicle.csv` | `737.0+ MB` | `199.6+ MB` | **-73%** |
| `collision.csv` | `619.0+ MB` | `283.7+ MB` | **-54%** |

Au total, nous √©conomisons **environ 873 MB de RAM**, ce qui est consid√©rable !

```python
# Chargement optimis√© des v√©hicules
df_vehicle = pd.read_csv("data/vehicle.csv", usecols=VEHICLE_FIELDS, dtype=DTYPES_VEHICLE)

# Chargement optimis√© des collisions
df_collision = pd.read_csv("data/collision.csv", usecols=COLLISION_FIELD, dtype=DTYPES_COLLISION)
```

-----

## ü§ù Fusion des Donn√©es

Les deux DataFrames (`df_vehicle` et `df_collision`) sont fusionn√©s en un seul DataFrame (`df`) en utilisant `collision_index` comme cl√© de jointure.

  * Une **jointure interne (`how="inner"`)** est utilis√©e, ce qui signifie que seuls les enregistrements pr√©sents dans *les deux* fichiers seront pr√©sents dans le DataFrame final.

```python
df = pd.merge(df_collision, df_vehicle, on="collision_index", how="inner")
```

### Pourquoi une jointure interne ?

Le choix d'une jointure **interne** plut√¥t qu'externe est d√©lib√©r√© :
* **Coh√©rence des donn√©es** : Nous voulons uniquement des accidents o√π nous avons √† la fois les informations sur la collision ET sur le v√©hicule
* **Pr√©diction r√©aliste** : Dans un contexte r√©el, si nous n'avons pas d'information sur le v√©hicule impliqu√©, nous ne pourrions pas faire de pr√©diction avec notre mod√®le
* **Qualit√© > Quantit√©** : Mieux vaut avoir moins de donn√©es mais compl√®tes que beaucoup de donn√©es avec des valeurs manquantes

-----

## üßπ Nettoyage et Filtrage Initial

Un premier ensemble de filtres est appliqu√© pour nettoyer le jeu de donn√©es fusionn√©.

### Suppression des valeurs manquantes

```python
df = df.dropna()
```

**Justification** : Les valeurs `NaN` posent plusieurs probl√®mes :
* Incompatibilit√© avec de nombreux algorithmes de ML
* Source potentielle de biais si les donn√©es manquantes ne sont pas al√©atoires
* Complexit√© accrue si imputation n√©cessaire
* Dans notre cas, nous avons suffisamment de donn√©es pour nous permettre de supprimer les lignes incompl√®tes

### Filtrage g√©ographique

```python
df = df[df.local_authority_ons_district != -1]
df = df[df.local_authority_ons_district.apply(lambda x: x[0] == "E")]
```

**Justification** : 
* **Exclusion des codes invalides (-1)** : Donn√©es de localisation manquantes ou corrompues
* **Focus sur l'Angleterre (codes "E")** : Les syst√®mes routiers, r√©glementations et infrastructures peuvent varier entre l'Angleterre, l'√âcosse et le Pays de Galles. En se concentrant sur l'Angleterre, nous √©vitons d'introduire de la variance g√©ographique non d√©sir√©e
* **Homog√©n√©it√©** : Un mod√®le entra√Æn√© sur des donn√©es homog√®nes g√©n√©ralisera mieux

### Filtrage des zones urbaines/rurales

```python
df = df[df.urban_or_rural_area.isin([1, 2])]
```

**Justification** : 
* **1** = Urbain, **2** = Rural : Ce sont des cat√©gories claires et bien d√©finies
* **3** = "Unallocated" : Cat√©gorie ambigu√´ qui pourrait introduire du bruit
* La distinction urbain/rural est un pr√©dicteur potentiellement important (vitesses diff√©rentes, types de routes diff√©rents)

-----

## üî¨ Ing√©nierie des Variables (Feature Engineering)

Plusieurs colonnes sont transform√©es pour les rendre exploitables par un mod√®le.

### `vehicle_type` (Type de v√©hicule)

L'objectif est de binariser cette variable en **Voiture (1)** ou **Moto (0)**. Les v√©hicules non list√©s ci-dessous sont exclus.

| Cat√©gorie | Codes Bruts | Valeur Finale |
| :--- | :--- | :--- |
| **Moto** | `[2, 3, 4, 5, 23, 97, 103, 104, 105, 106]` | **`0`** |
| **Voiture** | `[8, 9, 19, 108, 109, 110]` | **`1`** |

```python
df = df[df.vehicle_type.isin(TARGETED_CARS + TARGETED_MOTORCYCLES)]
df['vehicle_type'] = df['vehicle_type'].replace(TARGETED_CARS, 1)
df['vehicle_type'] = df['vehicle_type'].replace(TARGETED_MOTORCYCLES, 0)
```

**Pourquoi se limiter aux voitures et motos ?**
* **Volume de donn√©es** : Ces deux cat√©gories repr√©sentent la grande majorit√© des accidents
* **Comparabilit√©** : Les voitures et motos ont des profils de risque diff√©rents mais comparables
* **Exclusion du bruit** : V√©hicules sp√©ciaux (bus, camions, v√©hicules agricoles) ont des dynamiques d'accident tr√®s diff√©rentes
* **Simplicit√©** : Facilite l'interpr√©tation du mod√®le

**Note finale** : Seules les **voitures** (`vehicle_type == 1`) sont conserv√©es pour l'analyse finale, et la colonne `vehicle_type` est ensuite supprim√©e.

**Pourquoi ne garder que les voitures ?**
* **Homog√©n√©it√©** : Les motos ont un profil de risque radicalement diff√©rent (gravit√© beaucoup plus √©lev√©e, facteurs de risque diff√©rents)
* **Objectif du mod√®le** : Pr√©dire la gravit√© pour les voitures, le cas d'usage le plus courant
* **Performance** : Un mod√®le sp√©cialis√© sur les voitures sera plus performant qu'un mod√®le g√©n√©raliste

### `propulsion_code` (Type de propulsion)

Cette variable est filtr√©e mais finalement **supprim√©e** du dataset.

```python
df = df[df.propulsion_code.isin(PROPULSION_THERMIQUE + PROPULSTION_ECTRIQUE_HYBRIDE)]
df = df.drop(columns=["propulsion_code"])
```

**Pourquoi filtrer puis supprimer ?**
* **Filtrage** : On exclut les types de propulsion rares ou non d√©finis (ex: propulsion √† hydrog√®ne, donn√©es manquantes) pour garder la coh√©rence
* **Suppression** : Apr√®s analyse exploratoire, cette variable s'est av√©r√©e peu pr√©dictive de la gravit√©. Les v√©hicules √©lectriques/hybrides sont encore relativement r√©cents et leur effet est probablement d√©j√† captur√© par `age_of_vehicle`

### `date` et `time` (Date et heure de l'accident)

Les colonnes `date` et `time` sont utilis√©es pour extraire de nouvelles caract√©ristiques temporelles.

```python
df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')
df['day'] = df['date'].dt.day_name()
df['month'] = df['date'].dt.month
df['hour'] = df['time'].str.split(':').str[0].astype("int8")
df.day = df.day.map(DAY_MAPPING).astype("int8")  # Lundi=0, Dimanche=6
```

**Justification de la d√©composition temporelle** :

1. **`day` (Jour de la semaine)** :
   * **Hypoth√®se** : Les accidents de week-end sont diff√©rents (loisirs, alcool) des accidents en semaine (trajet travail)
   * **Encodage num√©rique** : 0-6 permet aux mod√®les de ML de capturer une relation ordinale

2. **`month` (Mois de l'ann√©e)** :
   * **Saisonnalit√©** : Conditions m√©t√©o, luminosit√©, vacances scolaires varient selon les mois
   * **Trafic** : Pics de circulation en √©t√© (vacances) vs hiver

3. **`hour` (Heure de la journ√©e)** :
   * **Tr√®s pr√©dictif** : La nuit (fatigue, alcool, visibilit√©) vs le jour
   * **Heures de pointe** : Comportements de conduite diff√©rents
   * **Granularit√©** : 24 valeurs permettent de capturer des patterns fins

**Pourquoi supprimer la date originale ?**
* √âvite le surapprentissage sur des dates sp√©cifiques (ex: "le 15/08/2019 est dangereux")
* Les features d√©riv√©es (`day`, `month`, `hour`) capturent l'information utile de mani√®re g√©n√©ralisable

### `sex_of_driver` (Sexe du conducteur)

```python
df = df[~df.sex_of_driver.isin([3, -1])]
```

**Justification** : 
* **1** = Masculin, **2** = F√©minin : Cat√©gories claires
* **3** = "Not known" / "Autre" : Donn√©es ambigu√´s ou manquantes
* **-1** = Donn√©es manquantes
* Cette variable peut capturer des diff√©rences de comportement au volant document√©es dans la litt√©rature

### `speed_limit` (Limite de vitesse)

```python
df = df[df.speed_limit.isin([30, 60, 40, 70, 50, 20])]
df.speed_limit = df.speed_limit.astype("int8")
```

**Justification** :
* **Limites standard** : Ce sont les limites de vitesse officielles au Royaume-Uni
* **Exclusion des valeurs aberrantes** : √âlimine les erreurs de saisie (ex: 999, 0)
* **Pr√©dicteur cl√©** : La vitesse est fortement corr√©l√©e √† la gravit√© des accidents
* **Conversion int8** : Apr√®s validation, on peut √©conomiser de la m√©moire

### `collision_severity` (Variable Cible)

C'est la variable cible (Y). Elle est transform√©e en probl√®me de classification binaire : **Grave (1)** vs **L√©ger (0)**.

| Gravit√© (Entr√©e) | Description | Valeur Finale (Sortie) |
| :--- | :--- | :--- |
| `1` | Fatal | **`1`** |
| `2` | Serious | **`1`** |
| `3` | Slight | **`0`** |

```python
df.collision_severity = (df.collision_severity != 3).astype("int8")
```

**Pourquoi binariser ?**
* **Objectif m√©tier** : Le syst√®me d'urgence doit d√©cider : "Envoyer des moyens lourds ou l√©gers ?"
* **Simplicit√©** : Plus facile √† interpr√©ter qu'une classification √† 3 classes
* **D√©s√©quilibre** : Fatal (classe 1) est tr√®s rare. En la fusionnant avec Serious, on √©quilibre mieux les classes
* **R√©alisme** : Fatal et Serious n√©cessitent tous deux une r√©ponse d'urgence prioritaire

-----

## üóëÔ∏è Filtrage Final et Finalisation

Des filtres suppl√©mentaires sont appliqu√©s pour exclure les donn√©es non pertinentes ou inconnues, ainsi que pour limiter les plages de valeurs.

### Filtrage des conditions de luminosit√©

```python
df = df[df.light_conditions.isin([1, 4, 5, 6])]
```

**Cat√©gories conserv√©es** :
* 1 = Daylight (Jour)
* 4 = Darkness - lights lit (Nuit - √©clairage allum√©)
* 5 = Darkness - lights unlit (Nuit - √©clairage non allum√©)
* 6 = Darkness - no lighting (Nuit - pas d'√©clairage)

**Pourquoi exclure les autres ?** : Cat√©gories comme "Unknown" ou "Data missing" n'apportent pas d'information

### Filtrage du type de route et m√©t√©o

```python
df = df[~df.road_type.isin([9, -1])]
df = df[~df.weather_conditions.isin([8, 9, -1])]
```

**Logique** : On exclut syst√©matiquement :
* **9** = "Unknown" : Information non disponible
* **-1** = "Data missing" : Donn√©es manquantes
* **8** (m√©t√©o) = "Other" : Cat√©gorie fourre-tout peu informative

### Filtrage des √¢ges

```python
df = df[~df.age_of_vehicle.isin([-1])]
df = df[~df.age_of_driver.isin([-1])]
df = df[df.age_of_driver >= 17]
df = df[df.age_of_driver <= 87]
df = df[df.age_of_vehicle >= 0]
df = df[df.age_of_vehicle <= 22]
```

**Justification des bornes** :

**√Çge du conducteur (17-87 ans)** :
* **Minimum 17 ans** : √Çge l√©gal minimum pour conduire au Royaume-Uni
* **Maximum 87 ans** : Au-del√†, les donn√©es deviennent tr√®s rares et potentiellement aberrantes (erreurs de saisie)
* **Distribution** : Capture 99%+ des conducteurs r√©els

**√Çge du v√©hicule (0-22 ans)** :
* **Minimum 0 ans** : V√©hicules neufs
* **Maximum 22 ans** : Au-del√†, volume tr√®s faible et v√©hicules potentiellement atypiques (v√©hicules de collection)
* **R√©alisme** : Correspond au parc automobile r√©el sur les routes

### Suppression des colonnes inutiles

```python
df.drop_duplicates()
df = df.drop(columns=["date", "collision_index", "local_authority_ons_district", "time"])
df = df[df.vehicle_type == 1].drop(columns=["vehicle_type"])
```

**Pourquoi supprimer ces colonnes ?**

* **`date` et `time`** : Information d√©j√† extraite dans `day`, `month`, `hour`
* **`collision_index`** : Identifiant unique, inutile pour la pr√©diction (risque de surapprendre)
* **`local_authority_ons_district`** : Trop granulaire (centaines de valeurs), utilis√© uniquement pour le filtrage
* **`vehicle_type`** : Apr√®s avoir gard√© uniquement les voitures, cette colonne est constante

-----

## üìä Dataset Final

Apr√®s l'ensemble du processus de nettoyage et de transformation, le dataset final contient :

**Dimensions**: **4,839,131 lignes √ó 12 colonnes**

**Colonnes finales**:
- `collision_severity` (int8) - **Variable cible** - 0=L√©ger, 1=Grave
- `road_type` (int8) - Type de route (rond-point, chauss√©e unique, etc.)
- `speed_limit` (int8) - Limite de vitesse en mph
- `light_conditions` (int8) - Conditions de luminosit√©
- `weather_conditions` (int8) - Conditions m√©t√©orologiques
- `urban_or_rural_area` (int8) - Zone urbaine (1) ou rurale (2)
- `sex_of_driver` (int8) - Sexe du conducteur
- `age_of_driver` (int8) - √Çge du conducteur (17-87 ans)
- `age_of_vehicle` (int8) - √Çge du v√©hicule (0-22 ans)
- `day` (int8) - Jour de la semaine (0=Lundi, 6=Dimanche)
- `month` (int8) - Mois de l'ann√©e (1-12)
- `hour` (int8) - Heure de la journ√©e (0-23)

**Utilisation m√©moire**: **~92.3 MB** (r√©duction drastique par rapport aux ~1.3 GB initiaux !)

**Qualit√© des donn√©es** :
* ‚úÖ Aucune valeur manquante
* ‚úÖ Toutes les variables sont num√©riques (compatibles ML)
* ‚úÖ Types optimis√©s (int8)
* ‚úÖ Plages de valeurs valid√©es
* ‚úÖ Dataset homog√®ne et coh√©rent

-----

## üíæ Export

Le DataFrame final, nettoy√© et transform√©, est sauvegard√© au format **Parquet**. Ce format est optimis√© pour le stockage et la lecture rapide des donn√©es analytiques.

```python
df.to_parquet("./data/clean_dataset.parquet")
```

**Pourquoi Parquet plut√¥t que CSV ?**

| Crit√®re | CSV | Parquet | Gagnant |
|---------|-----|---------|---------|
| **Taille du fichier** | ~500 MB | ~50 MB | ‚úÖ **Parquet** (10x plus petit) |
| **Vitesse de lecture** | Lent | Tr√®s rapide | ‚úÖ **Parquet** |
| **Pr√©servation des types** | ‚ùå Non | ‚úÖ Oui | ‚úÖ **Parquet** |
| **Compression** | ‚ùå Non | ‚úÖ Oui | ‚úÖ **Parquet** |
| **Lisibilit√© humaine** | ‚úÖ Oui | ‚ùå Non | CSV |

**Parquet est le choix optimal pour** :
* Le machine learning (lecture rapide de grandes quantit√©s de donn√©es)
* La pr√©servation exacte des types de donn√©es
* L'√©conomie d'espace disque
* Les pipelines de donn√©es en production